{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用spacy 进行分块\n",
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理及分块，剔除数字和特殊符号\n",
    "def chunking(text, model, clean_pattern='[0-9-/\\n\\t]+') :\n",
    "    clean_text = re.sub(clean_pattern, '', text.strip().lower())\n",
    "    \n",
    "    doc = model(clean_text)\n",
    "    chunks = []\n",
    "    last_end = 0\n",
    "    for chunk_start, chunk_end, _ in doc.noun_chunks_iterator(doc) :\n",
    "        if last_end < chunk_start :\n",
    "            chunk_start = last_end\n",
    "        last_end = chunk_end\n",
    "        chunks.append(doc[chunk_start:chunk_end].text.strip()) \n",
    "        # ic(chunk_start, chunk_end)\n",
    "    if last_end < len(doc) :\n",
    "        chunks.append(doc[last_end:].text.strip())\n",
    "    return ','.join(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = data['product_name'].apply(lambda x : chunking(x, nlp))\n",
    "chunks.name='chunks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = set()\n",
    "for rec in chunks :\n",
    "    for s in rec.split(',') :\n",
    "        all_chunks.add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json        \n",
    "with open('chunks.json', 'w', encoding='utf8') as fp:\n",
    "    json.dump(list(all_chunks), fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测分块后的语言，后续步骤中如果是英语，则不翻译，如果是法语，则翻译成中文\n",
    "from py3langid.langid import LanguageIdentifier, MODEL_FILE\n",
    "identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE, norm_probs=True)\n",
    "identifier.set_languages(['en', 'fr'])\n",
    "\n",
    "def language_detetion(text, model) :\n",
    "    lans = []\n",
    "    for chunk in text.split(',') :\n",
    "        lang_id, prob = model.classify(chunk )\n",
    "        if lang_id == 'en' and prob > 0.99 :\n",
    "            lans.append('en')\n",
    "        else :\n",
    "            lans.append('fr')\n",
    "    return ','.join(lans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['product_name']].applymap(lambda x: re.sub('[\\n]', '', x)).merge(\n",
    "    pd.DataFrame(chunks), how='left', left_index=True, right_index=True\n",
    ").to_csv('data_chunk.csv',sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = chunks.apply(lambda x: language_detetion(x, identifier))\n",
    "lang.name = 'lang_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['product_name']].applymap(lambda x: re.sub('[\\n]', '', x)).merge(\n",
    "    chunks, how='left', left_index=True, right_index=True\n",
    ").merge(\n",
    "    lang, how='left', left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('lang_detect.csv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用mbart transformer多语言模型进行翻译\n",
    "需要安装transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "trans_tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "trans_model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, model, tokenizer, src_lan='fr_XX', tgt_lan='en_XX', max_len=20):\n",
    "    tokenizer.src_lang = src_lan\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lan],\n",
    "        max_length=max_len\n",
    "    )\n",
    "    output = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm going to learn to speak a little more frankly.\",\n",
       " '7 Moncler Frgmt Hiroshi Fujiwara - Hunor Vest']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate([\n",
    "    'je vais apprendre à parler un peu fran?ais.',\n",
    "    '7 Moncler Frgmt Hiroshi Fujiwara - Veste Hunor'], trans_model, trans_tokenizer, 'fr_XX', 'en_XX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我要学会坦白一点。', '7 Moncler Frgmt Hiroshi Fujiwara - Hunor Vest']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate([\n",
    "    \"I'm going to learn to speak a little more frankly.\",\n",
    "    '7 Moncler Frgmt Hiroshi Fujiwara - Hunor Vest'], trans_model, trans_tokenizer, 'en_XX', 'zh_CN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每1000条读取一次文件，翻译后保存到json文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('lang_detect.csv', sep='\\t', chunksize=1000)\n",
    "\n",
    "fr_zh = {}\n",
    "fr_en = {}\n",
    "for i, file_chunk in enumerate(data1) :\n",
    "    for record in file_chunk[['chunks', 'lang_id']].to_records(index=None) :\n",
    "        for chunk, lan in zip(record[0].split(','), record[1].split(',')):\n",
    "            if lan == 'en' and chunk not in fr_zh.keys():\n",
    "                fr_zh[chunk] = chunk\n",
    "            elif lan == 'fr' and chunk not in fr_zh.keys():\n",
    "                text_zh = translate(chunk, trans_model, trans_tokenizer, 'fr_XX', 'zh_CN')\n",
    "                text_en = translate(chunk, trans_model, trans_tokenizer, 'fr_XX', 'en_XX')\n",
    "                fr_zh[chunk] = text_zh\n",
    "                fr_en[chunk] = text_en\n",
    "                ic(i, chunk, text_zh, text_en)    \n",
    "            \n",
    "    with open('fr_zh_{}.json'.format(i), 'w', encoding='utf8') as fp:\n",
    "        json.dump(fr_zh, fp)\n",
    "    with open('fr_en_{}.json'.format(i), 'w', encoding='utf8') as fp:\n",
    "        json.dump(fr_en, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取词典并转换成题目要求的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(d): 9430\n"
     ]
    }
   ],
   "source": [
    "dict_fr_zh = []\n",
    "fr_zh_all = {}\n",
    "with open('map_fr_zh.json', 'r', encoding='utf8') as fp:\n",
    "    d = json.load(fp)\n",
    "    ic(len(d))\n",
    "\n",
    "for k, v in d.items() :\n",
    "\n",
    "    if isinstance(v, list) :\n",
    "        dict_fr_zh.append({'FR': k, 'CN': v[0]})\n",
    "        fr_zh_all[k] = v[0]\n",
    "    else :\n",
    "        dict_fr_zh.append({'FR': k, 'CN': v})\n",
    "        fr_zh_all[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use another dictionary from Tencent translation\n",
    "fr_zh_all = {}\n",
    "with open('fr_zh_map.json', 'r') as fp:\n",
    "    fr_zh_all = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dict_fr_zh.json', 'w', encoding='utf8') as fp: \n",
    "#     json.dump(dict_fr_zh, fp,  ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('map_fr_zh.json', 'w', encoding='utf8') as fp: \n",
    "#     json.dump(fr_zh_all, fp,  ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 按生成的词典翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('lang_detect.csv', sep='\\t', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = data2['product_name'].apply(lambda x: chunking(x, nlp, '[\\n\\t]+'))\n",
    "chunks.name='chunks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2[['product_name']].applymap(lambda x: re.sub('[\\n]', '', x)).merge(\n",
    "    chunks, how='left', left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def translate_by_dict(text, d,) :\n",
    "    try :\n",
    "        result = []\n",
    "        numbers = []\n",
    "        for chunk in text.split(','):\n",
    "            numbers += re.findall('\\w*\\d+\\w*', chunk)\n",
    "            clean_chunk = re.sub('[\\d-]+', '', chunk)\n",
    "            # ic(numbers, clean_chunk, chunk)\n",
    "            if clean_chunk in fr_zh_all.keys():\n",
    "                result.append(fr_zh_all[clean_chunk])\n",
    "            else :\n",
    "                result.append(clean_chunk)\n",
    "        return ' '.join(result + numbers)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        ic(chunk, numbers, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_zh_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data3['chunks'].apply(lambda x: translate_by_dict(x, fr_zh_all),)\n",
    "result.name = 'result' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Alexa手套真丝衬里\n",
       "1                                 sac fourre tout ceinture\n",
       "2             moncler jw anderson  doudoune courte 赫尔弗林恩 1\n",
       "3         moncler jw anderson  doudoune courte WinteFold 1\n",
       "4                            moncler 对于脸部  doudoune 让·西奥 1\n",
       "                               ...                        \n",
       "10014                                                 签名盗窃\n",
       "10015                                 案例 pour airpods 专业人士\n",
       "10016                                              案例 对于卡片\n",
       "10017                                           案例 带连帽衫字体栏\n",
       "10018                          案例 一种用于制造机动车辆的 de ping pong\n",
       "Name: result, Length: 10019, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = data3[['product_name', 'chunks']].applymap(lambda x: re.sub('[\\n]', '', x)).merge(\n",
    "    result, how='left', left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv('result2.csv',sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用Transformer翻译成英文，再从英文翻译成中文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data3[['product_name']].applymap(lambda x: re.sub('[\\n]', '', x)).apply(\n",
    "    lambda x : translate(x, trans_model, trans_tokenizer, 'fr_XX', 'zh_CN'), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer_fr_en = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "model_fr_en = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('lang_detect.csv', sep='\\t', chunksize=70)\n",
    "\n",
    "for i, file_chunk in enumerate(data1) :\n",
    "    tic = datetime.now()\n",
    "    \n",
    "    inputs = tokenizer(file_chunk['product_name'].values.tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        # forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lan],\n",
    "        max_length=20\n",
    "    )\n",
    "    result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    pd.DataFrame(result).to_csv('result_en.csv',mode='a', index=None, header=None)\n",
    "    toc = datetime.now()\n",
    "    # break\n",
    "    ic(i, str(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355e4c7bb9d8483fadad1323af8ce8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python37\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mayn\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a173a3fad346d1bc5523bb4ea841a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38708edd70624987a7c6c841160204f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/806k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd04e18afe564dd884736f0aeb0bdd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/805k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6951002967c43bc804f7a5083f23bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python37\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7ae1ea6a0b4bf6b6588fd2d5f635d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-zh\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1952年 - 泰瑞鞋']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '1952 - Terry Shoes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| i: 0, str(toc-tic): '0:00:07.291512'\n",
      "ic| i: 1, str(toc-tic): '0:00:07.509928'\n",
      "ic| i: 2, str(toc-tic): '0:00:07.708397'\n",
      "ic| i: 3, str(toc-tic): '0:00:08.092386'\n",
      "ic| i: 4, str(toc-tic): '0:00:07.969700'\n",
      "ic| i: 5, str(toc-tic): '0:00:07.810128'\n",
      "ic| i: 6, str(toc-tic): '0:00:08.130271'\n",
      "ic| i: 7, str(toc-tic): '0:00:08.219032'\n",
      "ic| i: 8, str(toc-tic): '0:00:07.705406'\n",
      "ic| i: 9, str(toc-tic): '0:00:07.708398'\n",
      "ic| i: 10, str(toc-tic): '0:00:08.184127'\n",
      "ic| i: 11, str(toc-tic): '0:00:08.396559'\n",
      "ic| i: 12, str(toc-tic): '0:00:08.003609'\n",
      "ic| i: 13, str(toc-tic): '0:00:08.443434'\n",
      "ic| i: 14, str(toc-tic): '0:00:07.663519'\n",
      "ic| i: 15, str(toc-tic): '0:00:07.988650'\n",
      "ic| i: 16, str(toc-tic): '0:00:08.035526'\n",
      "ic| i: 17, str(toc-tic): '0:00:07.959727'\n",
      "ic| i: 18, str(toc-tic): '0:00:07.822093'\n",
      "ic| i: 19, str(toc-tic): '0:00:08.177146'\n",
      "ic| i: 20, str(toc-tic): '0:00:07.814116'\n",
      "ic| i: 21, str(toc-tic): '0:00:07.770233'\n",
      "ic| i: 22, str(toc-tic): '0:00:08.130273'\n",
      "ic| i: 23, str(toc-tic): '0:00:07.728345'\n",
      "ic| i: 24, str(toc-tic): '0:00:07.971695'\n",
      "ic| i: 25, str(toc-tic): '0:00:08.731663'\n",
      "ic| i: 26, str(toc-tic): '0:00:07.881935'\n",
      "ic| i: 27, str(toc-tic): '0:00:07.719369'\n",
      "ic| i: 28, str(toc-tic): '0:00:08.845358'\n",
      "ic| i: 29, str(toc-tic): '0:00:08.115312'\n",
      "ic| i: 30, str(toc-tic): '0:00:07.676484'\n",
      "ic| i: 31, str(toc-tic): '0:00:07.511924'\n",
      "ic| i: 32, str(toc-tic): '0:00:07.554809'\n",
      "ic| i: 33, str(toc-tic): '0:00:07.351353'\n",
      "ic| i: 34, str(toc-tic): '0:00:07.415182'\n",
      "ic| i: 35, str(toc-tic): '0:00:07.868968'\n",
      "ic| i: 36, str(toc-tic): '0:00:08.903206'\n",
      "ic| i: 37, str(toc-tic): '0:00:08.097360'\n",
      "ic| i: 38, str(toc-tic): '0:00:08.442435'\n",
      "ic| i: 39, str(toc-tic): '0:00:07.574755'\n",
      "ic| i: 40, str(toc-tic): '0:00:07.383267'\n",
      "ic| i: 41, str(toc-tic): '0:00:07.609661'\n",
      "ic| i: 42, str(toc-tic): '0:00:07.721364'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-44-ea9a56f1bf10&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clone():                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 27 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, decorate_context)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 │   </span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_generator</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Python\\Python37\\lib\\site-packages\\transformers\\generation_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1466</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1463 │   │   │   │   </span>output_scores=output_scores,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1464 │   │   │   │   </span>return_dict_in_generate=return_dict_in_generate,                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1465 │   │   │   │   </span>synced_gpus=synced_gpus,                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1466 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>**model_kwargs,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1467 │   │   │   </span>)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1468 │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1469 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> is_beam_sample_gen_mode:                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Python\\Python37\\lib\\site-packages\\transformers\\generation_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2316</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">beam_search</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2313 │   │   │   # cannot be generated both before and after the `nn.functional.log_sof</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2314 │   │   │   </span>next_token_logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.adjust_logits_during_generation(next_token_lo <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2315 │   │   │   </span>next_token_scores = nn.functional.log_softmax(                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2316 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>next_token_logits, dim=-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2317 │   │   │   </span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (batch_size * num_beams, vocab_size)</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2318 │   │   │   </span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2319 │   │   │   </span>next_token_scores_processed = logits_processor(input_ids, next_token_s <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">d:\\Python\\Python37\\lib\\site-packages\\torch\\nn\\functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1923</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">log_softmax</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1920 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dim <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1921 │   │   </span>dim = _get_softmax_dim(<span style=\"color: #808000; text-decoration-color: #808000\">\"log_softmax\"</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.dim(), _stacklevel)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1922 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1923 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ret = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.log_softmax(dim)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1924 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1925 │   │   </span>ret = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.log_softmax(dim, dtype=dtype)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1926 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> ret                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-44-ea9a56f1bf10>\u001b[0m:\u001b[94m9\u001b[0m in \u001b[92m<module>\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33md:\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m:\u001b[94m27\u001b[0m in \u001b[92mdecorate_context\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 25 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 26 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.clone():                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 27 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 28 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, decorate_context)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 29 \u001b[0m\u001b[2m│   \u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_wrap_generator\u001b[0m(\u001b[96mself\u001b[0m, func):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33md:\\Python\\Python37\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m:\u001b[94m1466\u001b[0m in \u001b[92mgenerate\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1463 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput_scores=output_scores,                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1464 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mreturn_dict_in_generate=return_dict_in_generate,                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1465 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msynced_gpus=synced_gpus,                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1466 \u001b[2m│   │   │   │   \u001b[0m**model_kwargs,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1467 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1468 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1469 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m is_beam_sample_gen_mode:                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33md:\\Python\\Python37\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m:\u001b[94m2316\u001b[0m in \u001b[92mbeam_search\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2313 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# cannot be generated both before and after the `nn.functional.log_sof\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2314 \u001b[0m\u001b[2m│   │   │   \u001b[0mnext_token_logits = \u001b[96mself\u001b[0m.adjust_logits_during_generation(next_token_lo \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2315 \u001b[0m\u001b[2m│   │   │   \u001b[0mnext_token_scores = nn.functional.log_softmax(                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2316 \u001b[2m│   │   │   │   \u001b[0mnext_token_logits, dim=-\u001b[94m1\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2317 \u001b[0m\u001b[2m│   │   │   \u001b[0m)  \u001b[2m# (batch_size * num_beams, vocab_size)\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2318 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2319 \u001b[0m\u001b[2m│   │   │   \u001b[0mnext_token_scores_processed = logits_processor(input_ids, next_token_s \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33md:\\Python\\Python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m:\u001b[94m1923\u001b[0m in \u001b[92mlog_softmax\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1920 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m dim \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1921 \u001b[0m\u001b[2m│   │   \u001b[0mdim = _get_softmax_dim(\u001b[33m\"\u001b[0m\u001b[33mlog_softmax\u001b[0m\u001b[33m\"\u001b[0m, \u001b[96minput\u001b[0m.dim(), _stacklevel)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1922 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m dtype \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1923 \u001b[2m│   │   \u001b[0mret = \u001b[96minput\u001b[0m.log_softmax(dim)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1924 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1925 \u001b[0m\u001b[2m│   │   \u001b[0mret = \u001b[96minput\u001b[0m.log_softmax(dim, dtype=dtype)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1926 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m ret                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_en = pd.read_csv('result_en.csv', sep='\\t', chunksize=70, header=None)\n",
    "data_en.columns=['product_name']\n",
    "for i, file_chunk in enumerate(data1) :\n",
    "    tic = datetime.now()\n",
    "    inputs = tokenizer(file_chunk['product_name'].values.tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    generated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        # forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lan],\n",
    "        max_length=20\n",
    "    )\n",
    "    result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    pd.DataFrame(result).to_csv('result_zh.csv',mode='a', index=None, header=None)\n",
    "    toc = datetime.now()\n",
    "    # break\n",
    "    ic(i, str(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translate(data3['product_name'].values.tolist(), trans_model, trans_tokenizer, 'fr_XX', 'zh_CN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = pd.read_csv('result_en.csv', sep='\\t', chunksize=None, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sneakers Chain Reaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>full-length leather belt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Moncler JW Anderson - Short Helvellyn Double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Moncler JW Anderson - Short Wintefold Double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Moncler JW Anderson - Penygarder Denim Doudoune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Soft Leather Belt B-belt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Belt B-Belt black smooth leather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Belt BB Signature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Belt Baguette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Bekky belt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1820 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0                              Sneakers Chain Reaction \n",
       "1                              full-length leather belt\n",
       "2        1 Moncler JW Anderson - Short Helvellyn Double\n",
       "3        1 Moncler JW Anderson - Short Wintefold Double\n",
       "4     1 Moncler JW Anderson - Penygarder Denim Doudoune\n",
       "...                                                 ...\n",
       "1815                           Soft Leather Belt B-belt\n",
       "1816                   Belt B-Belt black smooth leather\n",
       "1817                                  Belt BB Signature\n",
       "1818                                      Belt Baguette\n",
       "1819                                         Bekky belt\n",
       "\n",
       "[1820 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_en"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4cdb330c5ea7232880705c0e79ad22649a7c708042624124f8ff95c4dc218f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
